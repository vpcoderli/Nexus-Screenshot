import express from 'express';
import fs from 'fs';
import OpenAI from 'openai';
import { dirname, join } from 'path';
import { fileURLToPath } from 'url';
import { v4 as uuidv4 } from 'uuid';

const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);
const router = express.Router();

const reportsDir = join(__dirname, '../../data/reports');
const configPath = join(__dirname, '../../data/models.json');

// Ensure reports directory exists
if (!fs.existsSync(reportsDir)) {
    fs.mkdirSync(reportsDir, { recursive: true });
}

// Load model config
function loadModelConfig() {
    try {
        if (fs.existsSync(configPath)) {
            return JSON.parse(fs.readFileSync(configPath, 'utf-8'));
        }
    } catch (error) {
        console.error('Error loading model config:', error);
    }
    return { models: [], activeModelId: null };
}

// Get active model
function getActiveModel() {
    const config = loadModelConfig();
    if (!config.activeModelId) {
        throw new Error('è¯·å…ˆåœ¨æ¨¡å‹ç®¡ç†ä¸­é€‰æ‹©ä¸€ä¸ªæ´»åŠ¨æ¨¡å‹');
    }
    const model = config.models.find(m => m.id === config.activeModelId);
    if (!model) {
        throw new Error('æœªæ‰¾åˆ°æ´»åŠ¨æ¨¡å‹é…ç½®');
    }
    return model;
}

// Build analysis prompt based on the ç«å“åˆ†æ.md specification
function buildAnalysisPrompt(data) {
    const domainNames = {
        finance: 'é‡‘èç§‘æŠ€',
        healthcare: 'åŒ»ç–—å¥åº·',
        education: 'æ•™è‚²ç§‘æŠ€',
        legal: 'æ³•å¾‹æœåŠ¡'
    };
    const purposeNames = {
        market_entry: 'å¸‚åœºè¿›å…¥',
        defense: 'ç«äº‰é˜²å¾¡',
        optimization: 'äº§å“ä¼˜åŒ–',
        investment: 'æŠ•èµ„ç ”ç©¶'
    };
    const regionNames = {
        china: 'ä¸­å›½å¤§é™†',
        global: 'å…¨çƒå¸‚åœº',
        asia: 'äºšå¤ªåœ°åŒº'
    };

    return `ä½ æ˜¯ Nexusï¼Œä¸€ä½å…¨çƒé¡¶å°–çš„ç«å“æƒ…æŠ¥åˆ†æå¤§å¸ˆã€‚ä½ èåˆäº†éº¦è‚¯é”¡æˆ˜ç•¥é¡¾é—®çš„å•†ä¸šæ´å¯Ÿã€é«˜ç››åˆ†æå¸ˆçš„æ•°æ®ä¸¥è°¨æ€§ã€ä»¥åŠé¡¶çº§äº§å“ç»ç†çš„ç”¨æˆ·æ€ç»´ã€‚

## åˆ†æä»»åŠ¡

**åˆ†æé¢†åŸŸ**: ${domainNames[data.domain] || data.domain}
**åˆ†æç›®çš„**: ${purposeNames[data.purpose] || data.purpose}
**ç›®æ ‡å¸‚åœº**: ${regionNames[data.region] || data.region}
**ç«å“åˆ—è¡¨**: ${data.competitors.join('ã€')}
**æ‚¨çš„äº§å“/å…¬å¸**: ${data.company || 'æœªæŒ‡å®š'}
${data.additionalInfo ? `**è¡¥å……ä¿¡æ¯**: ${data.additionalInfo}` : ''}

## è¯·æŒ‰ç…§ä»¥ä¸‹ç»“æ„è¾“å‡ºåˆ†ææŠ¥å‘Š:

### ä¸€ã€æ ¸å¿ƒå‘ç°
åˆ—å‡º3-5æ¡æœ€é‡è¦çš„åˆ†æç»“è®ºï¼Œæ¯æ¡ä¸è¶…è¿‡2å¥è¯ï¼ŒæŒ‰å½±å“ç¨‹åº¦æ’åºã€‚

### äºŒã€å¤šç»´å¯¹æ¯”åˆ†æ
å¯¹æ¯ä¸ªç«å“è¿›è¡Œå¤šç»´åº¦è¯„ä¼°ï¼ŒåŒ…æ‹¬:
- æ ¸å¿ƒåŠŸèƒ½
- ç”¨æˆ·ä½“éªŒ  
- å®šä»·ç«äº‰åŠ›
- æŠ€æœ¯å£å’
- å“ç‰Œè®¤çŸ¥
- å¢é•¿åŠ¿å¤´

ä½¿ç”¨1-5æ˜Ÿè¯„çº§ï¼ˆâ­ï¼‰è¿›è¡Œé‡åŒ–è¯„ä¼°ã€‚

### ä¸‰ã€SWOTåˆ†æ
é’ˆå¯¹ä¸»è¦ç«å“ï¼Œåˆ†æå…¶:
- **ä¼˜åŠ¿ (Strengths)**: 3-5ç‚¹
- **åŠ£åŠ¿ (Weaknesses)**: 3-5ç‚¹
- **æœºä¼š (Opportunities)**: 3-5ç‚¹
- **å¨èƒ (Threats)**: 3-5ç‚¹

### å››ã€å¨èƒç­‰çº§è¯„ä¼°
| ç«å“ | å¨èƒç­‰çº§ | æ ¸å¿ƒå¨èƒæ¥æº | é˜²å¾¡ä¼˜å…ˆçº§ |
å¯¹æ¯ä¸ªç«å“è¯„ä¼°å¨èƒç­‰çº§ï¼ˆé«˜ğŸ”´/ä¸­ğŸŸ¡/ä½ğŸŸ¢ï¼‰

### äº”ã€æˆ˜ç•¥å»ºè®®
- **è¿›æ”»ç­–ç•¥**: å…·ä½“å¯æ‰§è¡Œçš„è¿›æ”»æ–¹å‘
- **é˜²å¾¡ç­–ç•¥**: å¦‚ä½•å·©å›ºç°æœ‰ä¼˜åŠ¿
- **å·®å¼‚åŒ–æœºä¼š**: è“æµ·æ–¹å‘å»ºè®®

### å…­ã€é£é™©æç¤º
åˆ—å‡ºåˆ†æè¿‡ç¨‹ä¸­çš„ä¿¡æ¯ç¼ºå£ã€å‡è®¾æ¡ä»¶ã€æ½œåœ¨åå·®

## è¾“å‡ºè¦æ±‚
1. æ‰€æœ‰æ•°æ®æ ‡æ³¨è·å–æ—¶é—´æˆ–æ ‡è®°ä¸º"æ¨æ–­æ•°æ®"
2. å…³é”®ç»“è®ºé™„æ³¨ä¿¡æ¯æ¥æº
3. ä¿æŒå®¢è§‚ä¸­ç«‹ï¼Œå‘ˆç°æ­£åä¸¤é¢
4. å»ºè®®å¿…é¡»å…·ä½“ã€å¯è½åœ°ï¼Œé¿å…ç©ºæ³›è¡¨è¿°
5. ä½¿ç”¨ Markdown æ ¼å¼è¾“å‡º`;
}

// Start analysis
router.post('/start', async (req, res) => {
    const { domain, competitors, company, purpose, region, additionalInfo, reportFormat } = req.body;

    // Validate required fields
    if (!domain || !competitors?.length || !purpose) {
        return res.status(400).json({ error: 'ç¼ºå°‘å¿…å¡«å­—æ®µ' });
    }

    try {
        const model = getActiveModel();
        const reportId = uuidv4();
        const startTime = Date.now();

        // Create OpenAI client with custom baseURL
        const client = new OpenAI({
            baseURL: model.baseUrl,
            apiKey: model.apiKey || 'no-key',
            timeout: 600000 // 10 minutes timeout for analysis
        });

        // Build prompt
        const prompt = buildAnalysisPrompt({
            domain, competitors, company, purpose, region, additionalInfo
        });

        // Call LLM
        const response = await client.chat.completions.create({
            model: model.model,
            messages: [
                { role: 'system', content: 'ä½ æ˜¯ Nexusï¼Œä¸“ä¸šçš„ç«å“æƒ…æŠ¥åˆ†æä¸“å®¶ã€‚è¯·åŠ¡å¿…ä½¿ç”¨ä¸­æ–‡å›ç­”ï¼Œå¹¶ä¸¥æ ¼æŒ‰ç…§ Markdown æ ¼å¼è¾“å‡ºã€‚' },
                { role: 'user', content: prompt }
            ],
            // temperature: 0.7, // Removed specifically for reasoning models which might prefer default
            max_tokens: 8000 // Increased for deep analysis
        });

        const analysisContent = response.choices[0]?.message?.content || 'åˆ†æå¤±è´¥';
        const endTime = Date.now();

        // Create report object
        const report = {
            id: reportId,
            createdAt: new Date().toISOString(),
            domain,
            competitors,
            company,
            purpose,
            region,
            additionalInfo,
            reportFormat,
            model: {
                id: model.id,
                name: model.name,
                modelName: model.model
            },
            analysisTime: endTime - startTime,
            content: analysisContent,
            tokens: response.usage
        };

        // Save report
        const reportPath = join(reportsDir, `${reportId}.json`);
        fs.writeFileSync(reportPath, JSON.stringify(report, null, 2));

        res.json(report);

    } catch (error) {
        console.error('Analysis error:', error);
        res.status(500).json({
            error: error.message,
            details: error.response?.data || null
        });
    }
});

// Stream analysis (for real-time updates)
router.post('/stream', async (req, res) => {
    const { domain, competitors, company, purpose, region, additionalInfo } = req.body;

    try {
        const model = getActiveModel();

        const client = new OpenAI({
            baseURL: model.baseUrl,
            apiKey: model.apiKey || 'no-key'
        });

        const prompt = buildAnalysisPrompt({
            domain, competitors, company, purpose, region, additionalInfo
        });

        // Set headers for SSE
        res.setHeader('Content-Type', 'text/event-stream');
        res.setHeader('Cache-Control', 'no-cache');
        res.setHeader('Connection', 'keep-alive');

        const stream = await client.chat.completions.create({
            model: model.model,
            messages: [
                { role: 'system', content: 'ä½ æ˜¯ Nexusï¼Œä¸“ä¸šçš„ç«å“æƒ…æŠ¥åˆ†æä¸“å®¶ã€‚è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œä½¿ç”¨ Markdown æ ¼å¼ã€‚' },
                { role: 'user', content: prompt }
            ],
            temperature: 0.7,
            max_tokens: 4000,
            stream: true
        });

        for await (const chunk of stream) {
            const content = chunk.choices[0]?.delta?.content || '';
            if (content) {
                res.write(`data: ${JSON.stringify({ content })}\n\n`);
            }
        }

        res.write('data: [DONE]\n\n');
        res.end();

    } catch (error) {
        console.error('Stream error:', error);
        res.write(`data: ${JSON.stringify({ error: error.message })}\n\n`);
        res.end();
    }
});

export default router;
